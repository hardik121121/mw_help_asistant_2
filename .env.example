# =================================
# API KEYS
# =================================

# OpenAI API (for embeddings and query understanding)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Pinecone API (for vector database)
# Get your key from: https://app.pinecone.io/
PINECONE_API_KEY=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
PINECONE_ENVIRONMENT=gcp-starter  # e.g., gcp-starter, us-east-1-aws

# Cohere API (for re-ranking)
# Get your key from: https://dashboard.cohere.com/api-keys
COHERE_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Groq API (for LLM inference)
# Get your key from: https://console.groq.com/keys
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# =================================
# DOCUMENT PROCESSING CONFIG
# =================================

# Chunk settings (for hierarchical chunking)
CHUNK_SIZE=1500  # Characters per chunk (increased for complex topics)
CHUNK_OVERLAP=300  # Overlap between chunks (increased for continuity)
MIN_CHUNK_SIZE=200  # Minimum chunk size

# Heading detection thresholds (font sizes in points)
HEADING_1_SIZE=20
HEADING_2_SIZE=16
HEADING_3_SIZE=14
HEADING_4_SIZE=12

# =================================
# RETRIEVAL CONFIG
# =================================

# Vector search
VECTOR_TOP_K=30  # Number of vector search results

# BM25 search
BM25_TOP_K=30  # Number of BM25 results

# Re-ranking
RERANK_TOP_K=10  # Number of results after re-ranking
RERANK_MODEL=rerank-english-v3.0  # Cohere model

# Reciprocal Rank Fusion
RRF_K=60  # RRF constant for score normalization

# Page proximity expansion
PAGE_PROXIMITY=3  # Include Â±N pages around top result for context

# =================================
# GENERATION CONFIG
# =================================

# LLM settings
LLM_MODEL=llama-3.3-70b-versatile  # Groq model
LLM_TEMPERATURE=0.2  # Lower = more deterministic (0.0 to 1.0)
LLM_MAX_TOKENS=8192  # Maximum response length
LLM_CONTEXT_WINDOW=128000  # Model context window (128k tokens)

# Query understanding
ENABLE_QUERY_DECOMPOSITION=true  # Enable complex query decomposition
MAX_SUB_QUESTIONS=4  # Maximum sub-questions per complex query
QUERY_COMPLEXITY_THRESHOLD=10  # Word count threshold for decomposition

# =================================
# DATABASE CONFIG
# =================================

# Pinecone index settings
PINECONE_INDEX_NAME=watermelon-docs-v2
PINECONE_DIMENSION=3072  # OpenAI text-embedding-3-large
PINECONE_METRIC=cosine  # Similarity metric (cosine, euclidean, dotproduct)
PINECONE_CLOUD=aws  # Cloud provider (aws, gcp, azure)
PINECONE_REGION=us-east-1  # Region

# =================================
# IMAGE CONFIG
# =================================

MAX_IMAGES_PER_PAGE=5  # Maximum images to show per page
MAX_TOTAL_IMAGES=15  # Maximum total images in response

# =================================
# PATHS
# =================================

PDF_PATH=data/helpdocs.pdf
CACHE_DIR=cache
IMAGE_CACHE_DIR=cache/images
PROCESSED_PDF_PATH=cache/docling_processed.json
CHUNKS_PATH=cache/hierarchical_chunks.json
EMBEDDINGS_PATH=cache/hierarchical_embeddings.pkl

# =================================
# LOGGING & DEBUG
# =================================

LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
ENABLE_DEBUG_MODE=false  # Show detailed debug information in UI
ENABLE_QUERY_LOGGING=true  # Log all queries for analysis
LOG_FILE=logs/app.log  # Log file path

# =================================
# PERFORMANCE
# =================================

# Batch processing
EMBEDDING_BATCH_SIZE=100  # Chunks per embedding API call
PINECONE_BATCH_SIZE=100  # Vectors per upsert batch

# Rate limiting (seconds between API calls)
EMBEDDING_RATE_LIMIT=0.1
COHERE_RATE_LIMIT=0.05
GROQ_RATE_LIMIT=0.01

# Caching
ENABLE_QUERY_CACHE=true  # Cache query results
CACHE_EXPIRY=3600  # Cache expiry in seconds (1 hour)

# =================================
# EVALUATION CONFIG
# =================================

# Test queries location
TEST_QUERIES_PATH=tests/test_queries.json
EVALUATION_OUTPUT_DIR=tests/results

# Metrics tracking
TRACK_RETRIEVAL_METRICS=true  # Precision, Recall, MRR, NDCG
TRACK_GENERATION_METRICS=true  # Completeness, accuracy, formatting
TRACK_LATENCY=true  # Query processing time
TRACK_COST=true  # API costs per query
